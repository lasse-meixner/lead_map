---
title: "Understanding identification in pogit from the ground up"
format:
    html:
      code-fold: true
---

We ignore the issue of censoring for now since we know how to deal with that and focus on the identification of the parameters in the Poisson-logit model.

### Baseline

Let us start with with two correlated variables, $x$ and $z$, where $x$ is a poisson regressor and $z$ is an exclusion restriction used in the logit part of the model. This is the learn-bayes example:

```{r}
set.seed(1999)
library(mvtnorm)

n <- 1000
rho <- 0.5
S <- matrix(c(1, rho,
              rho, 1), 2, 2, byrow = TRUE)
x_z <- rmvnorm(n, sigma = S)
x <- x_z[,1] 
z <- x_z[,2] 

alpha <- 0.5
beta <- 1
log_mu <- alpha + beta * (x - mean(x))
ystar <- rpois(n, exp(log_mu))

gamma <- (-0.5)
delta <- 1.2
logit_pi <- gamma + delta * (z - mean(z))
y <- rbinom(n, size = ystar, prob = plogis(logit_pi))

true_params <- c(alpha = alpha, beta = beta, gamma = gamma, delta = delta)
```

This model is identified:

```{r}
library(cmdstanr)

thinned_poisson <- cmdstan_model("thinned_poisson.stan") # takes int N, and vectors y, x, z
dat <- list(N = n, y = y, x = x, z = z)

fit <- thinned_poisson$sample(data = dat, chains = 4, parallel_chains = 4, refresh = 500)
```

```{r}
fit$summary() |>
    knitr::kable(digits = 2)
```

This agrees with the true parameters. The sampling is also efficient - the effective sample size is large and the Rhat is close to 1.

```{r}
library(bayesplot)
library(ggplot2)

# auxiliary function to plot diagnostics (posterior draws, trace plots)

plot_diagnostics <- function(fit){
    draws <- fit$draws(format = "draws_df") |>
        dplyr::select(-lp__)

    fig1 <- mcmc_areas(draws, prob = 0.9) + ggtitle("Posterior draws") +
        theme_minimal()

    fig2 <- mcmc_trace(draws) + ggtitle("Trace plots") + theme_minimal()

    fig3 <- mcmc_rank_ecdf(draws, prob = 0.99, plot_diff = TRUE) + ggtitle("Cumulative rank plots (difference)") +
    theme_minimal()

    # potentially add plot for divergent transitions

    list(fig1, fig2, fig3)
}

plot_diagnostics(fit)
```

The parameters in the logit model are more or less right, but very imprecise. There are two sources of this: 1) the excluded variable $z$ is correlated with the poisson regressor $x$ 2) the intercepts are not well identified.

Let us try fixing priors on both intercepts. I fix a prior on the logit intercept in accordance with the suggestion from the *Statistical Rethinking* playlist (Frank's recommendation). Since the logit takes the linear $\gamma + \delta z$ as predictions for the the log-odds, if these values range from $(-4,4)$, they essentially cover the entire probability spectrum from 0 to 1.

```{r}
# sample

intercepts <- rnorm(n*10, 0, 1.5)
p  <- plogis(intercepts)
# plot density and histogram
hist(p, breaks = 20, freq = FALSE, main = expression(paste("logit(p) = ", alpha)), xlab = "p")
lines(density(p), col = "red")
```

This gives a uniform-like distribution for the prior probabilities, so I will use this as a very weak prior for $\gamma$.

Not on the Poisson side, I pretend to have information about the mean $\alpha$ based on domain knowledge. In our data, we have national averages from NHANES about the prevalence of elevated blood lead counts. I simulate this by adding a weak prior to the true value of $\alpha$.

The new model looks as follows:

```{r}
thinned_poisson_prior <- cmdstan_model("thinned_poisson_w_priors.stan") 
thinned_poisson_prior$print()
```

Sampling with priors:

```{r}
# add alpha prior variance to data
dat$alpha_prior_var <- 0.5
fit_prior <- thinned_poisson_prior$sample(data = dat, chains = 4, parallel_chains = 4, refresh = 500)

fit_prior$summary() |>
    knitr::kable(digits = 2)
```

Does it make things more precise?

```{r}
plot_diagnostics(fit_prior)
```

The posterior distribution, although efficiently sampled, looks essentially identical. The priors seem to have little effect for the precision on the parameters on the logit side.

### Adding x to the logit

Now, let us add the poisson regressor $x$ to the logit part of the model and see if including it on both sides messes up identification.

```{r}
# re-simulate data
kappa <- 0.5
logit_pi <- gamma + delta * (z - mean(z)) + kappa * (x - mean(x)) # NEW!
y <- rbinom(n, size = ystar, prob = plogis(logit_pi)) # NEW!
true_params <- c(alpha = alpha, beta = beta, gamma = gamma, delta = delta, kappa = kappa) # NEW
```

In the STAN code we add the poisson regressor $x$ to the logit part of the model:

```{r}
thinned_poisson_x_priors <- cmdstan_model("thinned_poisson_w_priors_x_logit.stan")
# sample
fit_x_prior <- thinned_poisson_x_priors$sample(data = dat, chains = 4, parallel_chains = 4, refresh = 500)

fit_x_prior$summary() |>
    knitr::kable(digits = 2)
```

Convergence is still good!

```{r}
plot_diagnostics(fit_x_prior)
```

In our data, sampling of the posteriors of the poisson parameters breaks.

### Suppression

Is the issue with our data then just that the data does not vary enough that the non-linearities in the model can find these distributions?

```{r}
# suppress data based on 70% threshold (0 is not suppressed though)
threshold <- as.integer(quantile(y, 0.7)[[1]])
y_suppressed <- ifelse(y <= threshold, ifelse(y > 0, "s", 0), y)
is_suppressed <- y_suppressed == "s"

# demean x and z
x_demeaned <- x - mean(x)
z_demeaned <- z - mean(z)

dat_suppressed <- list(N_obs = as.integer(n-sum(is_suppressed)),
                       N_cens = as.integer(sum(is_suppressed)),
                       y_obs = y[!is_suppressed],
                       threshold = threshold,
                       x_obs = x_demeaned[!is_suppressed],
                       x_cens = x_demeaned[is_suppressed],
                       z_obs = z_demeaned[!is_suppressed],
                       z_cens = z_demeaned[is_suppressed],
                       alpha_prior_var = 0.5)

thinned_poisson_suppressed <- cmdstan_model("thinned_poisson_w_p_x_sup.stan")
fit_suppressed <- thinned_poisson_suppressed$sample(data = dat_suppressed, chains = 4, parallel_chains = 4, refresh = 500)

fit_suppressed$summary() |>
    knitr::kable(digits = 2)
```

```{r}
true_params
```

```{r}
plot_diagnostics(fit_suppressed)
```

Censoring clearly reduces the information contained in the data and thereby increases the posterior uncertainty. Except the intercept on gamma, the parameters are however estimates more or less correct (centered around the true values). There are no sampling problems, the chains explore the posterior efficiently as can be seen by Rhat convergence values and the traces.

### Including more correlation

My final hunch is that the real issue comes when variables to highly intercorrelated amongst themselves. Let's add another variable $w$ to the mix: First, we let it be super highly correlated with $z$ only, then with $x$.

*Intuitively, I imagine that things should break down when variables are very correlated on intervals of the covariate space on which the poisson and logit are **less curved**. So for the logit this should be for the values of* $z$ and $w$ where the logit is close to 0.5... This might be a diagnostic?

```{r}
# re-simulate data
n <- 1000
rho_high <- 0.9

S <- matrix(c(1, rho, 0,
              rho, 1, rho_high,
              0, rho_high, 1), 3, 3, byrow = TRUE)
D <- rmvnorm(n, sigma = S)
x <- D[,1]
z <- D[,2]
w <- D[,3]

# all parameters as before
omega_p <- -1 # NEW
omega_l <- 0.5 # NEW

log_mu <- alpha + beta * (x - mean(x)) + omega_p * (w - mean(w)) # NEW
ystar <- rpois(n, exp(log_mu))

logit_pi <- gamma + delta * (z - mean(z)) + kappa * (x - mean(x)) + omega_l * (w - mean(w)) # NEW
y <- rbinom(n, size = ystar, prob = plogis(logit_pi))

true_params <- c(alpha = alpha, beta = beta, gamma = gamma, delta = delta, kappa = kappa, omega_p = omega_p, omega_l = omega_l)
```

We again suppress the data as before:

```{r}
threshold <- as.integer(quantile(y, 0.7)[[1]])
y_suppressed <- ifelse(y <= threshold, ifelse(y > 0, "s", 0), y)
is_suppressed <- y_suppressed == "s"
```

We now need a STAN model that can handle arrays.

```{r}
thinned_poisson_multiple <- cmdstan_model("thinned_poisson_w_p_xw_sup.stan")

# prepare data
x_demeaned <- x - mean(x)
z_demeaned <- z - mean(z)
w_demeaned <- w - mean(w)

dat_suppressed <- list(N_obs = as.integer(n-sum(is_suppressed)),
                       N_cens = as.integer(sum(is_suppressed)),
                       y_obs = y[!is_suppressed],
                       threshold = threshold,
                       x_obs = x_demeaned[!is_suppressed],
                       x_cens = x_demeaned[is_suppressed],
                       z_obs = z_demeaned[!is_suppressed],
                       z_cens = z_demeaned[is_suppressed],
                       w_obs = w_demeaned[!is_suppressed],
                       w_cens = w_demeaned[is_suppressed],
                       alpha_prior_var = 0.5)


fit_suppressed_multiple <- thinned_poisson_multiple$sample(data = dat_suppressed, chains = 4, parallel_chains = 4, refresh = 500)

fit_suppressed_multiple$summary() |>
    knitr::kable(digits = 2)
```

Evidently, this ruins identification of parameters on the logit (which is not suprising). The posterior is absurdly wide on the logit parameters, and all chains converge very poorly and do not mix well. The question is how this affects the poisson parameters:

```{r}
plot_diagnostics(fit_suppressed_multiple)
```

The poisson parameters do not vary as wildly, however, the numerical issues on the logit side of course spill into sampling efficiency, as we can see when plotting only poisson parameters:

```{r}
mcmc_areas(fit_suppressed_multiple$draws(format="draws_df") |> dplyr::select(c(alpha, beta, omega_p)), prob = 0.5) + theme_minimal()
```

Here we see the bi-modal peaks that we also saw in our data.
